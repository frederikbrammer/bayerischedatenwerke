{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ec1626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.49.0 in /Users/frederikbrammer/Projects/bayerischedatenwerke/.venv/lib/python3.13/site-packages (4.49.0)\n",
      "Requirement already satisfied: torch in /Users/frederikbrammer/Projects/bayerischedatenwerke/.venv/lib/python3.13/site-packages (2.7.0)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: filelock in /Users/frederikbrammer/Projects/bayerischedatenwerke/.venv/lib/python3.13/site-packages (from transformers==4.49.0) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /Users/frederikbrammer/Projects/bayerischedatenwerke/.venv/lib/python3.13/site-packages (from transformers==4.49.0) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/frederikbrammer/Projects/bayerischedatenwerke/.venv/lib/python3.13/site-packages (from transformers==4.49.0) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/frederikbrammer/Projects/bayerischedatenwerke/.venv/lib/python3.13/site-packages (from transformers==4.49.0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/frederikbrammer/Projects/bayerischedatenwerke/.venv/lib/python3.13/site-packages (from transformers==4.49.0) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/frederikbrammer/Projects/bayerischedatenwerke/.venv/lib/python3.13/site-packages (from transformers==4.49.0) (2024.11.6)\n",
      "Requirement already satisfied: requests in /Users/frederikbrammer/Projects/bayerischedatenwerke/.venv/lib/python3.13/site-packages (from transformers==4.49.0) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/frederikbrammer/Projects/bayerischedatenwerke/.venv/lib/python3.13/site-packages (from transformers==4.49.0) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/frederikbrammer/Projects/bayerischedatenwerke/.venv/lib/python3.13/site-packages (from transformers==4.49.0) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/frederikbrammer/Projects/bayerischedatenwerke/.venv/lib/python3.13/site-packages (from transformers==4.49.0) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/frederikbrammer/Projects/bayerischedatenwerke/.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.49.0) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/frederikbrammer/Projects/bayerischedatenwerke/.venv/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers==4.49.0) (4.13.2)\n",
      "Requirement already satisfied: setuptools in /Users/frederikbrammer/Projects/bayerischedatenwerke/.venv/lib/python3.13/site-packages (from torch) (79.0.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/frederikbrammer/Projects/bayerischedatenwerke/.venv/lib/python3.13/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/frederikbrammer/Projects/bayerischedatenwerke/.venv/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/frederikbrammer/Projects/bayerischedatenwerke/.venv/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/frederikbrammer/Projects/bayerischedatenwerke/.venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/frederikbrammer/Projects/bayerischedatenwerke/.venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/frederikbrammer/Projects/bayerischedatenwerke/.venv/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/frederikbrammer/Projects/bayerischedatenwerke/.venv/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/frederikbrammer/Projects/bayerischedatenwerke/.venv/lib/python3.13/site-packages (from requests->transformers==4.49.0) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/frederikbrammer/Projects/bayerischedatenwerke/.venv/lib/python3.13/site-packages (from requests->transformers==4.49.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/frederikbrammer/Projects/bayerischedatenwerke/.venv/lib/python3.13/site-packages (from requests->transformers==4.49.0) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/frederikbrammer/Projects/bayerischedatenwerke/.venv/lib/python3.13/site-packages (from requests->transformers==4.49.0) (2025.4.26)\n",
      "Using cached pandas-2.2.3-cp313-cp313-macosx_11_0_arm64.whl (11.3 MB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [pandas]━━━━━━━━━━━\u001b[0m \u001b[32m2/3\u001b[0m [pandas]\n",
      "\u001b[1A\u001b[2KSuccessfully installed pandas-2.2.3 pytz-2025.2 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers==4.49.0 torch pandas tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363cc550",
   "metadata": {},
   "source": [
    "## Download all BMW court cases from courtlistener.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a6373ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d5366de",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching cases from: https://www.courtlistener.com/api/rest/v4/search/?q=bmw\n",
      "Collected 20 cases, total: 20\n",
      "Fetching cases from: https://www.courtlistener.com/api/rest/v4/search/?cursor=cz0xMzguMjMwNDcmcz00OTAzNjY1JnQ9byZkPTIwMjUtMDQtMjY%3D&q=bmw\n",
      "Collected 20 cases, total: 40\n",
      "Fetching cases from: https://www.courtlistener.com/api/rest/v4/search/?cursor=cz0xMjkuMDU0OTImcz0yNzc1ODE1JnQ9byZkPTIwMjUtMDQtMjY%3D&q=bmw\n",
      "Collected 20 cases, total: 60\n",
      "Fetching cases from: https://www.courtlistener.com/api/rest/v4/search/?cursor=cz0xMjEuODM5NDEmcz03MzE4ODMwJnQ9byZkPTIwMjUtMDQtMjY%3D&q=bmw\n",
      "Collected 20 cases, total: 80\n",
      "Fetching cases from: https://www.courtlistener.com/api/rest/v4/search/?cursor=cz0xMTQuMjQ1OSZzPTY4OTc2MDAmdD1vJmQ9MjAyNS0wNC0yNg%3D%3D&q=bmw\n",
      "Collected 20 cases, total: 100\n",
      "Fetching cases from: https://www.courtlistener.com/api/rest/v4/search/?cursor=cz0xMDYuOTczNTUmcz0yMDU3MjAyJnQ9byZkPTIwMjUtMDQtMjY%3D&q=bmw\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFetching cases from: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnext_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# Make the request with a small delay to avoid rate limiting\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m response = requests.get(next_url, headers=headers)\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Check if request was successful\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Base API endpoint\n",
    "base_url = \"https://www.courtlistener.com/api/rest/v4/search/?q=bmw\"\n",
    "\n",
    "# Headers to make it look like a browser request\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Initialize list to store all cases\n",
    "all_cases = []\n",
    "\n",
    "# Counter for number of cases collected\n",
    "total_cases_collected = 0\n",
    "max_cases = 10000\n",
    "\n",
    "# Initialize next_url to the base URL\n",
    "next_url = base_url\n",
    "\n",
    "# Loop until we've collected enough cases or there are no more pages\n",
    "while next_url and total_cases_collected < max_cases:\n",
    "    print(f\"Fetching cases from: {next_url}\")\n",
    "    \n",
    "    # Make the request with a small delay to avoid rate limiting\n",
    "    time.sleep(0.2)\n",
    "    response = requests.get(next_url, headers=headers)\n",
    "    \n",
    "    # Check if request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse JSON response\n",
    "        data = response.json()\n",
    "        \n",
    "        # Extract results\n",
    "        results = data.get('results', [])\n",
    "        \n",
    "        # Add these results to our collection\n",
    "        all_cases.extend(results)\n",
    "        total_cases_collected = len(all_cases)\n",
    "        \n",
    "        print(f\"Collected {len(results)} cases, total: {total_cases_collected}\")\n",
    "        \n",
    "        # Get URL for the next page\n",
    "        next_url = data.get('next')\n",
    "        \n",
    "        # If we've reached the limit, break the loop\n",
    "        if total_cases_collected >= max_cases:\n",
    "            break\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data: Status code {response.status_code}\")\n",
    "        print(response.text)\n",
    "        break\n",
    "\n",
    "# Trim to exactly max_cases if we have more\n",
    "if len(all_cases) > max_cases:\n",
    "    all_cases = all_cases[:max_cases]\n",
    "\n",
    "# Save to JSON file\n",
    "output_file = \"bmw_court_cases.json\"\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(all_cases, f)\n",
    "\n",
    "print(f\"Successfully collected {len(all_cases)} BMW court cases and saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcacd092",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "# Load the JSON file\n",
    "with open(\"bmw_court_cases.json\", \"r\") as f:\n",
    "    bmw_cases = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38b5746e",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "bmw_cases = bmw_cases[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a452cebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading text for 100 cases...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading case texts:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limited for case ID: 7323818, waiting 10 seconds before retry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading case texts:   0%|          | 0/100 [00:08<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 45\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;66;03m# Process each case sequentially with a progress bar\u001b[39;00m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, case \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(bmw_cases), total=\u001b[38;5;28mlen\u001b[39m(bmw_cases), desc=\u001b[33m\"\u001b[39m\u001b[33mDownloading case texts\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     case_id, text = \u001b[43mfetch_case_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcase\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m text:\n\u001b[32m     47\u001b[39m         bmw_cases[i][\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m] = text\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mfetch_case_text\u001b[39m\u001b[34m(case)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response.status_code == \u001b[32m429\u001b[39m:  \u001b[38;5;66;03m# Too Many Requests\u001b[39;00m\n\u001b[32m     21\u001b[39m     \u001b[38;5;66;03m# Wait longer and retry once\u001b[39;00m\n\u001b[32m     22\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRate limited for case ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mid\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, waiting 10 seconds before retry\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m     response = requests.get(\u001b[33m\"\u001b[39m\u001b[33mhttps://www.courtlistener.com/api/rest/v4/opinions/\u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mid\u001b[39m,\n\u001b[32m     25\u001b[39m                            headers=headers)\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m response.status_code == \u001b[32m200\u001b[39m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Define function to fetch case text for a single case\n",
    "def fetch_case_text(case):\n",
    "    absolute_url = case[\"absolute_url\"]\n",
    "    id = absolute_url.replace(\"/opinion/\", \"\").split(\"/\")[0]\n",
    "    \n",
    "    # Headers with user agent to make it look like a browser request\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Add delay to avoid rate limiting\n",
    "        time.sleep(1.0)  # Increased delay to 1 second\n",
    "        \n",
    "        response = requests.get(\"https://www.courtlistener.com/api/rest/v4/opinions/\" + id,\n",
    "                               headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            case_data = response.json()\n",
    "            return id, case_data.get(\"plain_text\", \"\")\n",
    "        elif response.status_code == 429:  # Too Many Requests\n",
    "            # Wait longer and retry once\n",
    "            print(f\"Rate limited for case ID: {id}, waiting 10 seconds before retry\")\n",
    "            time.sleep(10)\n",
    "            response = requests.get(\"https://www.courtlistener.com/api/rest/v4/opinions/\" + id,\n",
    "                                   headers=headers)\n",
    "            if response.status_code == 200:\n",
    "                case_data = response.json()\n",
    "                return id, case_data.get(\"plain_text\", \"\")\n",
    "            else:\n",
    "                print(f\"Retry failed for case ID: {id}, status code: {response.status_code}\")\n",
    "                return id, \"\"\n",
    "        else:\n",
    "            print(f\"Failed to fetch data for case ID: {id}, status code: {response.status_code}\")\n",
    "            return id, \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching case ID: {id}, error: {str(e)}\")\n",
    "        return id, \"\"\n",
    "\n",
    "# Sequential downloads instead of parallel\n",
    "print(f\"Downloading text for {len(bmw_cases)} cases...\")\n",
    "case_id_to_text = {}\n",
    "\n",
    "# Process each case sequentially with a progress bar\n",
    "for i, case in tqdm(enumerate(bmw_cases), total=len(bmw_cases), desc=\"Downloading case texts\"):\n",
    "    case_id, text = fetch_case_text(case)\n",
    "    if text:\n",
    "        bmw_cases[i][\"text\"] = text\n",
    "        case_id_to_text[case_id] = text\n",
    "\n",
    "# Save updated cases to JSON file\n",
    "output_file = \"bmw_court_cases_with_text.json\"\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(bmw_cases, f)\n",
    "\n",
    "print(f\"Successfully updated {len(case_id_to_text)} cases with text and saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69b19522",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mbmw_cases\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[31mKeyError\u001b[39m: 'text'"
     ]
    }
   ],
   "source": [
    "bmw_cases[0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f8262a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "def average_pool(last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "# Use MPS (Metal Performance Shaders) if available\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Each input text should start with \"query: \" or \"passage: \", even for non-English texts.\n",
    "# For tasks other than retrieval, you can simply use the \"query: \" prefix.\n",
    "input_texts = ['query: how much protein should a female eat',\n",
    "               'query: 南瓜的家常做法',\n",
    "               \"passage: As a general guideline, the CDC's average requirement of protein for women ages 19 to 70 is 46 grams per day. But, as you can see from this chart, you'll need to increase that if you're expecting or training for a marathon. Check out the chart below to see how much protein you should be eating each day.\",\n",
    "               \"passage: 1.清炒南瓜丝 原料:嫩南瓜半个 调料:葱、盐、白糖、鸡精 做法: 1、南瓜用刀薄薄的削去表面一层皮,用勺子刮去瓤 2、擦成细丝(没有擦菜板就用刀慢慢切成细丝) 3、锅烧热放油,入葱花煸出香味 4、入南瓜丝快速翻炒一分钟左右,放盐、一点白糖和鸡精调味出锅 2.香葱炒南瓜 原料:南瓜1只 调料:香葱、蒜末、橄榄油、盐 做法: 1、将南瓜去皮,切成片 2、油锅8成热后,将蒜末放入爆香 3、爆香后,将南瓜片放入,翻炒 4、在翻炒的同时,可以不时地往锅里加水,但不要太多 5、放入盐,炒匀 6、南瓜差不多软和绵了之后,就可以关火 7、撒入香葱,即可出锅\"]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('intfloat/multilingual-e5-large')\n",
    "model = AutoModel.from_pretrained('intfloat/multilingual-e5-large').to(device)\n",
    "\n",
    "# Tokenize the input texts\n",
    "batch_dict = tokenizer(input_texts, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "batch_dict = {k: v.to(device) for k, v in batch_dict.items()}  # Move to MPS\n",
    "    \n",
    "\n",
    "# Get the model outputs\n",
    "with torch.no_grad():  # Disable gradient computation for inference\n",
    "    outputs = model(**batch_dict)\n",
    "\n",
    "# Average pool the outputs\n",
    "embedding = average_pool(outputs.last_hidden_state, batch_dict[\"attention_mask\"])\n",
    "\n",
    "# Normalize the embedding\n",
    "embedding = F.normalize(embedding, p=2, dim=1)\n",
    "\n",
    "# normalize embeddings\n",
    "embeddings = F.normalize(embedding, p=2, dim=1)\n",
    "scores = (embeddings[:2] @ embeddings[2:].T) * 100\n",
    "print(scores.tolist())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
